<!--  -->
<!-- Linear Regression is a statistical method to model the relationship between 
a dependent variable and one or more independent variables by fitting a straight line to the observed data points. -->


Linear Regression:
<!-- Univariate: Using one feature to predict the target.
Multivariate: Using multiple features to predict the target. -->
<!-- 
<!-- Least Square Method:
<!-- Technique to find the best-fitting line by minimizing the sum of squared differences between observed and predicted values.

Measuring Performance:

<!-- MSE: Average of squared errors.
RMSE: Square root of MSE.
R-squared: Proportion of variance explained by the model. -->

<!-- Example: -->
Predicting house prices based on size and location.
Forecasting sales using advertising expenditure.
<!--  -->
Training: Data to train the model.
Testing: Data to evaluate model performance.


<!-- 
Logistic Regression: Classifies data into two categories by fitting a logistic curve to the observed data.

Predicting binary outcomes means that Logistic Regression is used to classify data into two categories or classes, typically represented as 0 and 1. For example, it can predict whether an email is spam or not spam,

Differentiate between Linear and Logistic Regression: Linear Regression predicts continuous outcomes, while Logistic Regression predicts binary outcomes. -->


<!-- 
Confusion Matrix:
A table used to evaluate the performance of a classification model.
It summarizes the counts of correct and incorrect predictions made by the model.
Heatmap:
A graphical representation of data using colors.
In a confusion matrix, a heatmap visually highlights the distribution of correct and incorrect predictions.
True positives and true negatives are usually represented by one color, while false positives and false negatives are represented by another. -->


<!-- ● Number of True Positive (TP) : Number of instances which are actually labelled as positive
and the predicted class by classifier is also positive.

● Number of True Negative (TN) : Number of instances which are actually labelled as negative
and the predicted class by classifier is also negative.

● Number of False Positive (FP) : Number of instances which are actually labelled as negative
and the predicted class by classifier is positive.

● Number of False Negative (FN): Number of instances which are actually labelled as positive
and the class predicted by the classifier is negative. -->

<!-- Naïve Bayes Classifier can be used for Classification of categorical data. -->